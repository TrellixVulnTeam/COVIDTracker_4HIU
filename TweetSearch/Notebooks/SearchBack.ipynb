{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source activate twitterCOVID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy import OAuthHandler, AppAuthHandler\n",
    "from tweepy import API, TweepError\n",
    "######### Importing with relative path\n",
    "import importlib.util\n",
    "spec = importlib.util.spec_from_file_location(\"secrets\", \"../secrets.py\")\n",
    "foo = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(foo)\n",
    "#from ../secrets import *\n",
    "##########################################\n",
    "from textblob import TextBlob\n",
    "import os\n",
    "import json\n",
    "import dataset\n",
    "from datafreeze import freeze\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Consumer key authentication\n",
    "auth = AppAuthHandler(foo.consumer_key, foo.consumer_secret) #using appauthhandler to retreive at a faster rate\n",
    "\n",
    "# Access key authentication\n",
    "# auth.set_access_token(foo.access_token, foo.access_token_secret)\n",
    "\n",
    "# Set up the API with the authentication handler\n",
    "api = API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: SearchAPI is limited in many ways (max 100 tweets per query is just one of them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = api.search(q = \"covid\", until = \"2020-04-02\", count = 100, tweet_mode = \"extended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonres = [resi._json for resi in search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(jsonres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>full_text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>metadata</th>\n",
       "      <th>source</th>\n",
       "      <th>in_reply_to_status_id</th>\n",
       "      <th>...</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>lang</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wed Apr 01 23:59:59 +0000 2020</td>\n",
       "      <td>1245501195554369536</td>\n",
       "      <td>1245501195554369536</td>\n",
       "      <td>RT @DonaldJTrumpJr: The same media wants to st...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 140]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>18781</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wed Apr 01 23:59:59 +0000 2020</td>\n",
       "      <td>1245501195373948929</td>\n",
       "      <td>1245501195373948929</td>\n",
       "      <td>RT @Econ_Marshall: Whatever happened to the Se...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 81]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wed Apr 01 23:59:59 +0000 2020</td>\n",
       "      <td>1245501195327848449</td>\n",
       "      <td>1245501195327848449</td>\n",
       "      <td>If I had a dollar...\" COVID edition:  If I had...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 281]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>78</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wed Apr 01 23:59:59 +0000 2020</td>\n",
       "      <td>1245501195315220480</td>\n",
       "      <td>1245501195315220480</td>\n",
       "      <td>@look_now Trotzdem können sie die Krankheit ve...</td>\n",
       "      <td>False</td>\n",
       "      <td>[10, 149]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'de', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>1.245501e+18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>de</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wed Apr 01 23:59:59 +0000 2020</td>\n",
       "      <td>1245501195273285632</td>\n",
       "      <td>1245501195273285632</td>\n",
       "      <td>RT @RexChapman: Sandra the orangutang started ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[0, 139]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'en', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>105067</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at                   id               id_str  \\\n",
       "0  Wed Apr 01 23:59:59 +0000 2020  1245501195554369536  1245501195554369536   \n",
       "1  Wed Apr 01 23:59:59 +0000 2020  1245501195373948929  1245501195373948929   \n",
       "2  Wed Apr 01 23:59:59 +0000 2020  1245501195327848449  1245501195327848449   \n",
       "3  Wed Apr 01 23:59:59 +0000 2020  1245501195315220480  1245501195315220480   \n",
       "4  Wed Apr 01 23:59:59 +0000 2020  1245501195273285632  1245501195273285632   \n",
       "\n",
       "                                           full_text  truncated  \\\n",
       "0  RT @DonaldJTrumpJr: The same media wants to st...      False   \n",
       "1  RT @Econ_Marshall: Whatever happened to the Se...      False   \n",
       "2  If I had a dollar...\" COVID edition:  If I had...      False   \n",
       "3  @look_now Trotzdem können sie die Krankheit ve...      False   \n",
       "4  RT @RexChapman: Sandra the orangutang started ...      False   \n",
       "\n",
       "  display_text_range                                           entities  \\\n",
       "0           [0, 140]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "1            [0, 81]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "2           [0, 281]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "3          [10, 149]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "4           [0, 139]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "\n",
       "                                            metadata  \\\n",
       "0  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "1  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "2  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "3  {'iso_language_code': 'de', 'result_type': 're...   \n",
       "4  {'iso_language_code': 'en', 'result_type': 're...   \n",
       "\n",
       "                                              source  in_reply_to_status_id  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" ...                    NaN   \n",
       "1  <a href=\"http://twitter.com/download/android\" ...                    NaN   \n",
       "2  <a href=\"https://mobile.twitter.com\" rel=\"nofo...                    NaN   \n",
       "3  <a href=\"http://twitter.com/download/iphone\" r...           1.245501e+18   \n",
       "4  <a href=\"https://mobile.twitter.com\" rel=\"nofo...                    NaN   \n",
       "\n",
       "   ... retweet_count  favorite_count favorited retweeted lang  \\\n",
       "0  ...         18781               0     False     False   en   \n",
       "1  ...            55               0     False     False   en   \n",
       "2  ...            12              78     False     False   en   \n",
       "3  ...             0               0     False     False   de   \n",
       "4  ...        105067               0     False     False   en   \n",
       "\n",
       "  extended_entities possibly_sensitive quoted_status_id quoted_status_id_str  \\\n",
       "0               NaN                NaN              NaN                  NaN   \n",
       "1               NaN                NaN              NaN                  NaN   \n",
       "2               NaN                NaN              NaN                  NaN   \n",
       "3               NaN                NaN              NaN                  NaN   \n",
       "4               NaN                NaN              NaN                  NaN   \n",
       "\n",
       "  quoted_status  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cracking Twitter APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From [link](https://bhaskarvk.github.io/2015/01/how-to-use-twitters-search-rest-api-most-effectively./). The seacrh method has some `max_id` and `since_id` arguments we can exploit to our advantage. These are like upper and lower boundaries for our tweets, and given tweets come sorted by post time, we can retrieve many many tweets going back up to 1 week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import jsonpickle\n",
    "import os\n",
    "\n",
    "searchQuery = \"covid\"\n",
    "maxTweets = 1000\n",
    "tweetsPerQry = 100 # max set by twitter api\n",
    "fName = \"LastWeek.csv\"\n",
    "\n",
    "# the api search output SearchObject is an object that can be turned into a list of json str with the _json method\n",
    "# the search object itself can be indexed like a list\n",
    "sinceID = None # no lower limit (as far as necessary)\n",
    "maxID = -1 #exploit negative indexing, last tweet\n",
    "tweetCount = 0\n",
    "# the ID is just an ordered number, If I tweet now and my tweet ID is 1 and\n",
    "# your tweet comes next your tweet id will be 2\n",
    "\n",
    "\n",
    "print(\"Downloading max {0} tweets\".format(maxTweets))\n",
    "\n",
    "with open(fName, 'w') as f:\n",
    "    while tweetCount < maxTweets:\n",
    "        try:\n",
    "            if (maxID<=0):\n",
    "                # if your maxID is negative (1st iteration) do this\n",
    "                if (not sinceID):\n",
    "                    new_tweets = api.search(q=searchQuery, count = tweetsPerQry)\n",
    "                else: # if sinceID exists set sinceID as that minimum\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                            since_id=sinceID)\n",
    "            else: # if maxID is positive ? \n",
    "                if (not sinceID): # if sinceID not defined don't set low boundary\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                            max_id=str(maxID - 1))\n",
    "                else: # if sinceID exist set low and up boundary\n",
    "                    new_tweets = api.search(q=searchQuery, count=tweetsPerQry,\n",
    "                                            max_id=str(maxID - 1),\n",
    "                                            since_id=sinceID)\n",
    "            if not new_tweets:\n",
    "                print(\"No more tweets found\")\n",
    "                break\n",
    "            for tweet in new_tweets:\n",
    "                f.write(jsonpickle.encode(tweet._json))\n",
    "            tweetCount += len(new_tweets)\n",
    "            print(\"Downloaded {0} tweets\".format(tweetCount))\n",
    "            maxID = new_tweets[-1].id # set maxID to the latest ID in the previous search\n",
    "        except TweepError as e:\n",
    "            # Just exit if any error\n",
    "            print(\"some error : \" + str(e))\n",
    "            break\n",
    "print (\"Downloaded {0} tweets, Saved to {1}\".format(tweetCount, fName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jsonpickle\n",
    "tweets = []\n",
    "\n",
    "for line in open(\"BackSearch/SomeKeywords.json\", \"r\"):\n",
    "    tweets.append(json.loads(line))\n",
    "tweets = pd.DataFrame(tweets)\n",
    "tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = json.loads(\"BackSearch/SomeKeywords.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_json(\"BackSearch/SomeKeywords.json\", lines = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.read_csv(\"BackSearch/SomeKeywords.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonres[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TwitterCOVID",
   "language": "python",
   "name": "twittercovid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
